{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Character Encoding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmsl+sj/ObCjC0un1FgLID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jminango20/DataCleaning/blob/master/Character_Encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US0jE2Ad-Inp",
        "colab_type": "text"
      },
      "source": [
        "### Avoid UnicodeDecodeErrors when loading CSV files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ59eJmb-Zfs",
        "colab_type": "text"
      },
      "source": [
        "## What are encodings?\n",
        "\n",
        "Character encodings are specific sets of rules for mapping from raw binary byte strings (that look like this: 0110100001101001) to characters that make up human-readable text (like \"hi\"). \n",
        "\n",
        "Character encoding mismatches are less common today than they used to be, but it's definitely still a problem. There are lots of different character encodings, but the main one you need to know is UTF-8.\n",
        "\n",
        "UTF-8 is the standard text encoding. All Python code is in UTF-8 and, ideally, all your data should be as well. It's when things aren't in UTF-8 that you run into trouble.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjiOyKWA-Qwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start with a string\n",
        "before = \"This is the euro symbol: €\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0GKM1c0-nN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8da70114-9887-4a1c-db31-337ff88fa176"
      },
      "source": [
        "# check to see what datatype it is\n",
        "type(before)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VypqmW-8-zAC",
        "colab_type": "text"
      },
      "source": [
        "You can convert a string into bytes by specifying which encoding it's in:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyWXHwEe-sG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode it to a different encoding, replacing characters that raise errors\n",
        "after = before.encode(encoding='utf-8',errors='replace')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI9rG_vK-_mE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df422ee3-141a-4227-86bc-0f47e878a0a0"
      },
      "source": [
        "#check the type\n",
        "type(after)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bytes"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2KgvpPO_Lr2",
        "colab_type": "text"
      },
      "source": [
        "You'll see that it has a `b` in front of it, and then maybe some text after. \n",
        "\n",
        "Here you can see that our euro symbol has been replaced with some mojibake that looks like \"\\xe2\\x82\\xac\" when it's printed as if it were an ASCII string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF1T0-X8_GEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88fce6b0-00e3-4638-c06a-b456f84106b2"
      },
      "source": [
        "# take a look at what the bytes look like\n",
        "print(after)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'This is the euro symbol: \\xe2\\x82\\xac'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXQYigup_WiL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33e0625f-0707-407e-f1bd-576f174b0345"
      },
      "source": [
        "# convert it back to utf-8\n",
        "print(after.decode(encoding='utf-8'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the euro symbol: €\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiZWx_sy_eof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "3fedf91a-af7f-46dd-aa7e-69a28fb18806"
      },
      "source": [
        "# try to decode our bytes with the ascii encoding\n",
        "print(after.decode(encoding=\"ascii\"))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f8763e3e4ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# try to decode our bytes with the ascii encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mafter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ascii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 25: ordinal not in range(128)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwOHWmN9_twH",
        "colab_type": "text"
      },
      "source": [
        "## Reading in files with encoding problems\n",
        "\n",
        "Most files you'll encounter will probably be encoded with UTF-8. This is what Python expects by default, so most of the time you won't run into problems. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_peaYRMl_k8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helpful character encoding module\n",
        "import chardet\n",
        "\n",
        "# look at the first ten thousand bytes to guess the character encoding\n",
        "with open(\"../input/kickstarter-projects/ks-projects-201801.csv\", 'rb') as rawdata:\n",
        "    result = chardet.detect(rawdata.read(10000))\n",
        "\n",
        "# check what the character encoding might be\n",
        "print(result)\n",
        "\n",
        "# read in the file with the encoding detected by chardet\n",
        "kickstarter_2016 = pd.read_csv(\"../input/kickstarter-projects/ks-projects-201612.csv\", encoding='Windows-1252')\n",
        "\n",
        "# look at the first few lines\n",
        "kickstarter_2016.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXk5SshsAJha",
        "colab_type": "text"
      },
      "source": [
        "## Saving your files with UTF-8 encoding\n",
        "\n",
        "Finally, once you've gone through all the trouble of getting your file into UTF-8, you'll probably want to keep it that way. The easiest way to do that is to save your files with UTF-8 encoding. The good news is, since UTF-8 is the standard encoding in Python, when you save a file it will be saved as UTF-8 by default:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QPyc0acARA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save our file (will be saved as UTF-8 by default!)\n",
        "kickstarter_2016.to_csv(\"ks-projects-201801.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}